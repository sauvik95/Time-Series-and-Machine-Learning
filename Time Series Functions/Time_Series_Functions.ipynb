{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9764c49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader.data as web\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import l1_l2\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from arch.unitroot import PhillipsPerron\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from scipy.stats import norm\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.tsa.stattools import adfuller,kpss\n",
    "from arch.unitroot import PhillipsPerron\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b1fc63",
   "metadata": {},
   "source": [
    "# Function to convert datetime to date only in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d4e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S would be the DataFrame that we want to convert\n",
    "def date_time(S):\n",
    "    S.index = S.index.date\n",
    "    S.index = pd.to_datetime(S.index)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9dcfb1",
   "metadata": {},
   "source": [
    "# Function to convert quarterly data to monthly using Forwardfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3948cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    S = Dataframe to convert\n",
    "    n = Dividing factor (usually 1 if data is already in percentage form) \n",
    "''' \n",
    "\n",
    "def quarterly_to_monthly_forwardfill(S,n):\n",
    "    monthly = pd.DataFrame(S.dropna())\n",
    "    monthly.index = monthly.index.shift(3,freq='MS')\n",
    "    monthly = (monthly.asfreq('MS',method='ffill')/n).resample('M').max()\n",
    "    return monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c592700",
   "metadata": {},
   "source": [
    "# Function to create correlation heatmap for leading and lagging indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8699ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    data1 = Will contain dataframe\n",
    "    numshifts = Numbers of lead or lags that we want for our data\n",
    "    zero_or_one = 1 is for leading indicators and 0 for lagging indicators\n",
    "''' \n",
    "\n",
    "def leadlagheatmap(data1, numshifts, zero_or_one):\n",
    "    plt.figure(figsize=(15, 13))\n",
    "    if zero_or_one == 0:\n",
    "        target = data1.iloc[:,-1].shift(numshifts)\n",
    "        vars = data1.iloc[0:-numshifts,0:-1]\n",
    "        comblagged = pd.concat([vars, target], axis=1)\n",
    "        comblagged.dropna\n",
    "    else:\n",
    "        target = data1.iloc[0:-numshifts,-1]\n",
    "        vars = data1.iloc[:,0:-1].shift(numshifts)\n",
    "        comblagged = pd.concat([vars, target], axis=1)\n",
    "        comblagged.dropna\n",
    "    return sns.heatmap(comblagged.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc3d5d8",
   "metadata": {},
   "source": [
    "# Function to create training and testing data for time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c62a3b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    dep_data = Target data\n",
    "    indep_data = Predictors\n",
    "    shufflestate = Usually False if we want to maintain temporal order of time series data\n",
    "    testsize = Usually between 20-30%\n",
    "'''\n",
    "def traintestsplit(dep_data,indep_data, shufflestate, testsize):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dep_data, indep_data, shuffle=shufflestate, test_size=testsize)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f66ff",
   "metadata": {},
   "source": [
    "# Function to check for stationarity using KPSS, ADF and Philips Perron test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89e5b2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    varname = These are the column names of our dataframe\n",
    "    vardata = these are the datapoints of our dataframe\n",
    "    \n",
    "    The output would tell us whether each and every variable is stationary or not based on all 3 tests of stationarity\n",
    "'''\n",
    "def int_stat_test(varname, vardata):\n",
    "    # ADF Test\n",
    "    adfcnt = 0\n",
    "    adf = adfuller(vardata)\n",
    "    if adf[1] < 0.05:\n",
    "        adfcnt = 1\n",
    "    # KPSS Test\n",
    "    kpcnt = 0\n",
    "    kpstest = kpss(vardata)\n",
    "    if kpstest[1] > 0.05:\n",
    "        kpcnt = 1\n",
    "    # PP Test\n",
    "    ppcnt = 0\n",
    "    pptest = PhillipsPerron(vardata)\n",
    "    if pptest.pvalue< 0.05:\n",
    "        ppcnt = 1\n",
    "    if adfcnt + kpcnt + ppcnt >= 2:\n",
    "        print(varname, 'is stationary')\n",
    "    else:\n",
    "        print(varname, 'is not stationary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78f628a",
   "metadata": {},
   "source": [
    "# Function to plot components of our time series model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6b3ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    S = Dataframe to input\n",
    "    model_type = Usually 'additive'. 'multiplicative' models involve a logarithmic component which does not work for \n",
    "    negative returns\n",
    "'''\n",
    "def seasonalty_check(S,model_type):\n",
    "    data_columns = S.columns\n",
    "    for column in data_columns:\n",
    "        seasonal_decomposition = sm.tsa.seasonal_decompose(S[column], model=model_type)\n",
    "\n",
    "        # Plot the original time series, trend, seasonal, and residual components\n",
    "        fig, ax = plt.subplots(4, 1, figsize=(10, 8))\n",
    "        ax[0].plot(S.index, S[column], label='Original')\n",
    "        ax[0].legend(loc='best')\n",
    "        ax[1].plot(S.index, seasonal_decomposition.trend, label='Trend')\n",
    "        ax[1].legend(loc='best')\n",
    "        ax[2].plot(S.index, seasonal_decomposition.seasonal, label='Seasonal')\n",
    "        ax[2].legend(loc='best')\n",
    "        ax[3].plot(S.index, seasonal_decomposition.resid, label='Residual')\n",
    "        ax[3].legend(loc='best')\n",
    "\n",
    "        # Set the title of the plot as the column name\n",
    "        ax[0].set_title(column)\n",
    "\n",
    "    # Show the plots\n",
    "    return plt.tight_layout()\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c461255",
   "metadata": {},
   "source": [
    "# Function to create PACF and ACF Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c0a9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PACF_ACF_plot(S):\n",
    "    for column in range(len(S.columns)):\n",
    "        # Plot PACF\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        plot_pacf(S.iloc[:,column], lags=50, ax=ax)\n",
    "        ax.set_title('Partial Autocorrelation Function (PACF)')\n",
    "        plt.title(S.columns[column] + ' PACF')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot ACF\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        plot_acf(S.iloc[:,column], lags=50, ax=ax)\n",
    "        ax.set_title('Autocorrelation Function (ACF)')\n",
    "        plt.title(S.columns[column] + ' ACF')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0626c01",
   "metadata": {},
   "source": [
    "# Function to decompose our time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35fdd01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonality_trend_residual(S, model_type):\n",
    "    ccardata_seasonal = pd.DataFrame(index=S.index, columns=S.columns)\n",
    "    ccardata_trend = pd.DataFrame(index=S.index, columns=S.columns)\n",
    "    ccardata_residual = pd.DataFrame(index=S.index, columns=S.columns)\n",
    "    ccardata_SA = pd.DataFrame(index=S.index, columns=S.columns)\n",
    "    \n",
    "    for column in S.columns:\n",
    "        seasonal_decomposition = sm.tsa.seasonal_decompose(S[column], model=model_type)\n",
    "        deseasonalized = S[column] - seasonal_decomposition.seasonal\n",
    "\n",
    "        \n",
    "        ccardata_SA.loc[:, column] = deseasonalized\n",
    "        ccardata_seasonal.loc[:, column] = seasonal_decomposition.seasonal\n",
    "        ccardata_trend.loc[:, column] = seasonal_decomposition.trend\n",
    "        ccardata_residual.loc[:, column] = seasonal_decomposition.resid\n",
    "        \n",
    "\n",
    "        \n",
    "    return ccardata_seasonal, ccardata_trend, ccardata_residual,ccardata_SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820d4d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8599ad3",
   "metadata": {},
   "source": [
    "# ARIMA Model Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9353b01a",
   "metadata": {},
   "source": [
    "## Function to check best pdq order for ARIMA based on RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64b5595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    p_range, d_range, q_range = range of p,d,q values that we want to test\n",
    "    train_y = training set of our target variable\n",
    "    test_y = testing set of our target variable\n",
    "'''\n",
    "def ARIMA_pdq_order(p_range, d_range, q_range, train_y, test_y):\n",
    "    p_values = range(0, p_range)\n",
    "    d_values = range(0, d_range)\n",
    "    q_values = range(0, q_range)\n",
    "    \n",
    "    # Initialize variables\n",
    "    best_rmse = float('inf')\n",
    "    best_order = None\n",
    "    \n",
    "    # Generate all combinations of p, d, q values\n",
    "    order_combinations = list(itertools.product(p_values, d_values, q_values))\n",
    "    \n",
    "    for order in order_combinations:\n",
    "        try:\n",
    "            # Create and fit the ARIMA model\n",
    "            model = sm.tsa.ARIMA(train_y, order=order)\n",
    "            results = model.fit()\n",
    "            forecast_ARIMA = results.forecast(steps=len(test_y))\n",
    "            rmse = np.sqrt(mean_squared_error(test_y, forecast_ARIMA))\n",
    "            \n",
    "            # Check if current RMSE is better than the previous best\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_order = order\n",
    "        except:\n",
    "            continue\n",
    "                    \n",
    "    # Print the best order values and RMSE\n",
    "    return \"Best Order:\", best_order, \"Best RMSE:\", best_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f3025",
   "metadata": {},
   "source": [
    "## Function to give a table of statistical values for comparison of ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f0a522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    order = Best pdq order we got from above code\n",
    "'''\n",
    "def ARIMA_order_table(order, train_y, test_y):\n",
    "\n",
    "    # Create and fit the ARIMA model\n",
    "    model = sm.tsa.ARIMA(train_y, order=order)\n",
    "    results = model.fit()\n",
    "    forecast_ARIMA = results.forecast(steps=len(test_y))\n",
    "    rmse = np.sqrt(mean_squared_error(test_y, forecast_ARIMA))\n",
    "    mape = np.mean(np.abs((test_y - forecast_ARIMA) / test_y)) * 100\n",
    "    mae = mean_absolute_error(test_y, forecast_ARIMA)\n",
    "    r_squared = r2_score(test_y, forecast_ARIMA)\n",
    "    aic = results.aic\n",
    "    bic = results.bic\n",
    "\n",
    "    # Append the results to the table\n",
    "    results_df = pd.DataFrame([[order, rmse, mape, mae, r_squared,aic, bic]],\n",
    "                              columns=[\"Order\", \"RMSE\", \"MAPE\", \"MAE\", \"R-Squared\",\"AIC\", \"BIC\"])\n",
    "\n",
    "    # Print the results in tabular form\n",
    "    return (results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf986883",
   "metadata": {},
   "source": [
    "## Function to find in-sample and out-sample RMSE and predictions of ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79baad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARIMA_model_in(train_y,test_y,order):\n",
    "    model_ARIMA = sm.tsa.ARIMA(train_y, order=order)\n",
    "    results_ARIMA = model_ARIMA.fit()\n",
    "    forecast_ARIMA = results_ARIMA.forecast(steps=len(test_y))\n",
    "    predict = results_ARIMA.predict(start = '1997-01-31', end ='2017-12-31')\n",
    "    rmse = np.sqrt(mean_squared_error(predict,train_y))\n",
    "    return rmse,predict\n",
    "\n",
    "def ARIMA_model_out(train_y,test_y,order):\n",
    "    model_ARIMA = sm.tsa.ARIMA(train_y, order=order)\n",
    "    results_ARIMA = model_ARIMA.fit()\n",
    "    forecast_ARIMA = results_ARIMA.forecast(steps=len(test_y))\n",
    "    rmse = np.sqrt(mean_squared_error(forecast_ARIMA,test_y))\n",
    "    summary = results_ARIMA.summary()\n",
    "    return rmse,forecast_ARIMA,summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d4c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df80469b",
   "metadata": {},
   "source": [
    "# ARIMAX Model Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c694bb9e",
   "metadata": {},
   "source": [
    "## Function to check best pdq order for ARIMAX based on RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fbee14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Similar to ARIMA model. We have just included an exogenous variable here\n",
    "'''\n",
    "\n",
    "def ARIMAX_pdq_order(p_range, d_range, q_range, train_x, test_x, train_y, test_y):\n",
    "    p_values = range(0, p_range)\n",
    "    d_values = range(0, d_range)\n",
    "    q_values = range(0, q_range)\n",
    "\n",
    "    # Initialize variables\n",
    "    best_rmse = float('inf')\n",
    "    best_order = None\n",
    "\n",
    "    # Generate all combinations of p, d, q values\n",
    "    order_combinations = list(itertools.product(p_values, d_values, q_values))\n",
    "\n",
    "    for order in order_combinations:\n",
    "        try:\n",
    "            # Create and fit the ARIMAX model\n",
    "            model = sm.tsa.ARIMA(train_y, order=order, exog=train_x)\n",
    "            results = model.fit()\n",
    "            forecast_ARIMAX = results.forecast(steps=len(test_y), exog=test_x)\n",
    "            rmse = np.sqrt(mean_squared_error(test_y, forecast_ARIMAX))\n",
    "\n",
    "            # Check if current RMSE is better than the previous best\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_order = order\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # Print the best order values and RMSE\n",
    "    return \"Best Order:\", best_order, \"Best RMSE:\", best_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782534a",
   "metadata": {},
   "source": [
    "## Function to give a table of statistical values for comparison of ARIMAX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0127f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARIMAX_order_table(train_x, test_x, train_y, test_y, order):\n",
    "    # Create and fit the ARIMAX model\n",
    "    model = sm.tsa.ARIMA(train_y, exog=train_x, order=order)\n",
    "    results = model.fit()\n",
    "    forecast_ARIMAX = results.forecast(steps=len(test_y), exog=test_x)\n",
    "    rmse = np.sqrt(mean_squared_error(test_y, forecast_ARIMAX))\n",
    "    mape = np.mean(np.abs((test_y - forecast_ARIMAX) / test_y)) * 100\n",
    "    mae = mean_absolute_error(test_y, forecast_ARIMAX)\n",
    "    r_squared = r2_score(test_y, forecast_ARIMAX)\n",
    "    aic = results.aic\n",
    "    bic = results.bic\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    results_df = pd.DataFrame([[order, rmse, mape, mae, r_squared,aic, bic]],\n",
    "                              columns=[\"Order\", \"RMSE\", \"MAPE\", \"MAE\", \"R-Squared\",\"AIC\", \"BIC\"])\n",
    "\n",
    "    # Print the results in tabular form\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd4e03",
   "metadata": {},
   "source": [
    "## Function to find in-sample and out-sample RMSE and predictions of ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "012f623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARIMAX_model_in(train_x,test_x,train_y,test_y,order):\n",
    "    model_ARIMAX = sm.tsa.ARIMA(train_y, order=order, exog=train_x)\n",
    "    results_ARIMAX = model_ARIMAX.fit()\n",
    "    forecast_ARIMAX = results_ARIMAX.forecast(steps=len(test_y), exog=test_x)\n",
    "    predict = results_ARIMAX.predict(start = '1997-01-31', end ='2017-12-31')\n",
    "    rmse = np.sqrt(mean_squared_error(predict,train_y))\n",
    "    return rmse,predict\n",
    "\n",
    "def ARIMAX_model_out(train_x,test_x,train_y,test_y,order):\n",
    "    model_ARIMAX = sm.tsa.ARIMA(train_y, order=order, exog=train_x)\n",
    "    results_ARIMAX = model_ARIMAX.fit()\n",
    "    forecast_ARIMAX = results_ARIMAX.forecast(steps=len(test_y), exog=test_x)\n",
    "    rmse = np.sqrt(mean_squared_error(forecast_ARIMAX,test_y))\n",
    "    summary = results_ARIMAX.summary()\n",
    "    return rmse,forecast_ARIMAX,summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0403b098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba507bb0",
   "metadata": {},
   "source": [
    "# ARIMAX-GARCH Model Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16659a3b",
   "metadata": {},
   "source": [
    "## Function to check best pdq order for ARIMAX-GARCH based on RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e47f91cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    We have to input our training and testing set of our Independent and Dependent variables\n",
    "'''\n",
    "def find_best_arimax_garch_order(trainx_combined_SA, testx_combined_SA, trainy_combined_SA,testy_combined_SA):\n",
    "    p_values = range(1, 4)\n",
    "    d_values = range(0, 4)\n",
    "    q_values = range(1, 4)\n",
    "    pdq = list(itertools.product(p_values, d_values, q_values))\n",
    "\n",
    "    P_values = range(1, 4)\n",
    "    Q_values = range(1, 4)\n",
    "    pq = list(itertools.product(P_values, Q_values))\n",
    "\n",
    "    best_rmse = float('inf')\n",
    "    best_arima_order = None\n",
    "    best_garch_order = None\n",
    "\n",
    "    for arima_order in pdq:\n",
    "        for garch_order in pq:\n",
    "            # Create and fit the ARIMAX model\n",
    "            model = sm.tsa.ARIMA(trainy_combined_SA, order=arima_order, exog=trainx_combined_SA)\n",
    "            arima_results = model.fit()\n",
    "            arima_residuals = arima_results.resid\n",
    "            arima_pred = arima_results.forecast(steps=len(testy_combined_SA), exog=testx_combined_SA)\n",
    "\n",
    "            garch_model = arch.arch_model(arima_residuals, vol='Garch', p=garch_order[0], q=garch_order[1])\n",
    "            results = garch_model.fit()\n",
    "            garch_pred = results.forecast(horizon=len(testy_combined_SA))\n",
    "            garch_var = np.sqrt(garch_pred.variance.iloc[-1, :])\n",
    "            garch_var.index = testy_combined_SA.index\n",
    "            garch_mean = garch_var.mean()\n",
    "            total = garch_mean + arima_pred\n",
    "            rmse = np.sqrt(mean_squared_error(testy_combined_SA, total))\n",
    "\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_arima_order = arima_order\n",
    "                best_garch_order = garch_order\n",
    "\n",
    "    return best_arima_order, best_garch_order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def8a3e",
   "metadata": {},
   "source": [
    "## Function to give a table of statistical values for comparison of ARIMAX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3446906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arimax_garch_analysis(trainx_combined_SA, testx_combined_SA, trainy_combined_SA,testy_combined_SA):\n",
    "    # Fit ARIMAX model\n",
    "    model_arimax = sm.tsa.ARIMA(trainy_combined_SA, order=(2,0,2), exog=trainx_combined_SA)\n",
    "    arimax_results = model_arimax.fit()\n",
    "    arimax_residuals = arimax_results.resid\n",
    "    \n",
    "    # Perform GARCH modeling\n",
    "    garch_model = arch.arch_model(arimax_residuals, vol='Garch', p=3, q=3)\n",
    "    garch_results = garch_model.fit()\n",
    "    \n",
    "    # Generate ARIMAX-GARCH predictions\n",
    "    arimax_pred = arimax_results.forecast(steps=len(testy_combined_SA), exog=testx_combined_SA)\n",
    "    garch_pred = garch_results.forecast(horizon=len(testy_combined_SA))\n",
    "    a = np.sqrt(garch_pred.variance.iloc[-1, :])\n",
    "    a.index = testy_combined_SA.index\n",
    "    a_mean = a.mean()\n",
    "    total = arimax_pred + a_mean\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    rmse = np.sqrt(mean_squared_error(testy_combined_SA, total))\n",
    "    mape = np.mean(np.abs((testy_combined_SA - total) / testy_combined_SA)) * 100\n",
    "    mae = mean_absolute_error(testy_combined_SA, total)\n",
    "    r_squared = r2_score(testy_combined_SA, total)\n",
    "    aic = arimax_results.aic + garch_results.aic\n",
    "    bic = arimax_results.bic + garch_results.bic\n",
    "    \n",
    "    # Create output table\n",
    "    output_table = pd.DataFrame({\n",
    "        'ARIMAX-GARCH Order': [f'ARIMA{(2,0,2)}-GARCH({(3)}, {(3)})'],\n",
    "        'RMSE': [rmse],\n",
    "        'MAPE': [mape],\n",
    "        'MAE': [mae],\n",
    "        'R-squared': [r_squared],\n",
    "        'AIC': [aic],\n",
    "        'BIC': [bic]\n",
    "    })\n",
    "    \n",
    "    return output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63661c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcb5c2f3",
   "metadata": {},
   "source": [
    "# SARIMAX Model Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c3610",
   "metadata": {},
   "source": [
    "## Function to check best pdq order for SARIMAX based on RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7afa3b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SARIMAX_order(X_train, X_test, Y_train,Y_test,s):\n",
    "    p_values = range(1, 3)\n",
    "    d_values = range(0, 3)\n",
    "    q_values = range(1, 3)\n",
    "    pdq = list(itertools.product(p_values, d_values, q_values))\n",
    "\n",
    "    P_values = range(1, 3)\n",
    "    D_values = range(0, 3)\n",
    "    Q_values = range(1, 3)\n",
    "    S_values = s\n",
    "    pdqs = list(itertools.product(P_values, D_values, Q_values, S_values))\n",
    "\n",
    "    best_rmse = float('inf')\n",
    "    best_order = None\n",
    "    best_seasonal_order = None\n",
    "\n",
    "    for i in range(len(pdq)):\n",
    "        for j in range(len(pdqs)):\n",
    "            # Create and fit the SARIMAX model\n",
    "            model = sm.tsa.SARIMAX(Y_train, order=pdq[i], seasonal_order=pdqs[j], exog=X_train)\n",
    "            results = model.fit()\n",
    "            forecast_SARIMAX = results.forecast(steps=len(Y_test), exog=X_test)\n",
    "            rmse = np.sqrt(mean_squared_error(Y_test, forecast_SARIMAX))\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_order = pdq[i]\n",
    "                best_seasonal_order = pdqs[j]\n",
    "\n",
    "    print(f\"Order: {best_order}, Seasonal Order: {best_seasonal_order}, RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73adcfde",
   "metadata": {},
   "source": [
    "## Function to give a table of statistical values for comparison of SARIMAX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c98653b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SARIMAX_order_table(train_x, test_x, train_y, test_y, order, seasonal_order):\n",
    "    # Create and fit the SARIMAX model\n",
    "    model = sm.tsa.SARIMAX(train_y, exog=train_x, order=order, seasonal_order=seasonal_order)\n",
    "    results = model.fit()\n",
    "    forecast_SARIMAX = results.forecast(steps=len(test_y), exog=test_x)\n",
    "    rmse = np.sqrt(mean_squared_error(test_y, forecast_SARIMAX))\n",
    "    mape = np.mean(np.abs((test_y - forecast_SARIMAX) / test_y)) * 100\n",
    "    mae = mean_absolute_error(test_y, forecast_SARIMAX)\n",
    "    r_squared = r2_score(test_y, forecast_SARIMAX)\n",
    "    aic = results.aic\n",
    "    bic = results.bic\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    results_df = pd.DataFrame([[order, seasonal_order, rmse, mape, mae, r_squared, aic, bic]],\n",
    "                              columns=[\"Order\", \"Seasonal Order\", \"RMSE\", \"MAPE\", \"MAE\", \"R-squared\", \"AIC\", \"BIC\"])\n",
    "\n",
    "    # Print the results in tabular form\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57fb2e7",
   "metadata": {},
   "source": [
    "## Function to find in-sample and out-sample RMSE and predictions of SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "570781e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SARIMAX_model_in(train_x, test_x, train_y, test_y, order, seasonal_order):\n",
    "    model_SARIMAX = sm.tsa.SARIMAX(train_y, exog=train_x, order=order, seasonal_order=seasonal_order)\n",
    "    results_SARIMAX = model_SARIMAX.fit()\n",
    "    forecast_SARIMAX = results_SARIMAX.forecast(steps=len(test_y), exog=test_x)\n",
    "    predict = results_SARIMAX.predict(start='1997-01-31', end='2017-12-31')\n",
    "    rmse = np.sqrt(mean_squared_error(predict, train_y))\n",
    "    r_squared = r2_score(train_y, predict)\n",
    "    return rmse, predict,r_squared\n",
    "\n",
    "def SARIMAX_model_out(train_x, test_x, train_y, test_y, order, seasonal_order):\n",
    "    model_SARIMAX = sm.tsa.SARIMAX(train_y, exog=train_x, order=order, seasonal_order=seasonal_order)\n",
    "    results_SARIMAX = model_SARIMAX.fit()\n",
    "    forecast_SARIMAX = results_SARIMAX.forecast(steps=len(test_y), exog=test_x)\n",
    "    rmse = np.sqrt(mean_squared_error(forecast_SARIMAX, test_y))\n",
    "    r_squared = r2_score(test_y, forecast_SARIMAX)\n",
    "    summary_table = results_SARIMAX.summary()\n",
    "    return rmse, forecast_SARIMAX,r_squared,summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caac389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
